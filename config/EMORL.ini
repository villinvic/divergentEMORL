[Global]
LOGLEVEL = str INFO
PARAM_PORT = int 5556
EXP_PORT = int 5557
TRAJECTORY_LENGTH = int 80
BATCH_SIZE = int 16
EPSILON_GREEDY = float 0.01
MUJOCO_ENV = str Ant-v3

[Hub]
pop_size = int 20
n_offspring = int 1
mutation_rate = float 1.0
crossover_rate = float 0.33
k_random = int 2
init_time = int 10
train_time = int 180
save_traj_batch_chance = float 0.001
sample_state_chance = float 0.01
sample_size = int 20
ckpt_keep = int 5
min_entropy_ratio = float 0.
critical_entropy_ratio = float 0.
l = float 1.
moving_avg_size = int 300
bad_trend_maxcount = int 30000
epsilon = float 2
max_gen = int 8000
bad_score = float -52

[AC]

[Policy]

[Worker]
frameskip = int 4

[MeleeWorker]
char = str Falcon
opp_char = str Fox
pad_path = str Melee/dolphin/User/Pipes/

[Genotype]
brain_model = csv models/vtrace

[RewardShape]
variable_base = csv tables/reward_shaping_melee
perturb_chance = float 0.2
perturb_power = float 0.15
reset_chance = float 0.1

[LearningParams]
variable_base = csv tables/learning_params
perturb_chance = float 0.1
perturb_power = float 0.15
reset_chance = float 0.1

[EvolvingVariable]
history_max = int 100


